# Direct Preference Optimization
name: simpo
use_reference_model: true
# beta: Temperature parameter for the TDPO loss, typically something in the range of 0.1 to 0.5. We ignore the reference model as beta -> 0.
# alpha: Temperature parameter for the TDPO loss, used to adjust the impact of sequential kl divergence.
beta: 2.0
alpha: 0.0
gamma: 0.5



dataloader: 
  module_name: data.dataloader
  class_name: PairedPreferenceDataLoader

model:
  module_name: feature_alignment.model.simpo
  class_name: SimPOModel